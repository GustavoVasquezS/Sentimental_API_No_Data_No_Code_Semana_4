# ğŸ¯ SentimentAPI v4.0 - MultilingÃ¼e ES+PT

## ğŸ“‹ DescripciÃ³n del Proyecto

**SentimentAPI v4.0** es un MVP de anÃ¡lisis de sentimientos **multilingÃ¼e (EspaÃ±ol + PortuguÃ©s)** que combina un pipeline de Machine Learning en Python (TFâ€‘IDF + RegresiÃ³n LogÃ­stica calibrada) con un backend en Spring Boot y persistencia en PostgreSQL. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)
El sistema recibe textos libres (reseÃ±as/comentarios), predice **Negativo / Neutro / Positivo** y expone los resultados vÃ­a API REST, dejando el cÃ¡lculo de mÃ©tricas y visualizaciones al Frontend. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)

### Clasificaciones disponibles

- ğŸŸ¢ **Positivo** (estrellas 4â€“5)  
- ğŸŸ¡ **Neutro** (estrella 3)  
- ğŸ”´ **Negativo** (estrellas 1â€“2)

### CaracterÃ­sticas principales

- âœ… Modelo **multilingÃ¼e ES+PT** en un Ãºnico pipeline y artefacto `.joblib`.  
- âœ… Probabilidades **calibradas** y umbral dinÃ¡mico para `review_required`.  
- âœ… Persistencia de interacciones en **PostgreSQL** (usuarios, roles e historial de anÃ¡lisis).  
- âœ… Backend Spring Boot con endpoints de **registro/login** y consumo de la API de Python vÃ­a `WebClient`.  

***

## ğŸ•’ LÃ­nea de tiempo del MVP (v1 â†’ v4)

La evoluciÃ³n del proyecto sigue tres fases de Data Science mÃ¡s la integraciÃ³n completa en v4.  

### ğŸ”¹ Fase 1 â€” ExploraciÃ³n y baseline (v1 Â· EspaÃ±ol)

- Modelo inicial con **TFâ€‘IDF (unigramas/bigramas) + RegresiÃ³n LogÃ­stica** sobre reseÃ±as en espaÃ±ol. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)
- Limpieza basada en regex, sin lematizaciÃ³n ni pipelines pesados; foco en **factibilidad tÃ©cnica** y bajo costo computacional. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)

### ğŸ”¹ Fase 2 â€” Robustez estadÃ­stica (v2 Â· EspaÃ±ol)

- IncorporaciÃ³n de **Naive Bayes** como baseline comparativo y **cross-validation estratificada** para medir estabilidad.  
- IntroducciÃ³n de la regla de **revisiÃ³n humana por incertidumbre** (`review_required` cuando la probabilidad mÃ¡xima cae por debajo de un threshold).  

### ğŸ”¹ Fase 3 â€” Modelo productivo multilingÃ¼e (v3 Â· ES+PT)

- AmpliaciÃ³n del dataset a **EspaÃ±ol + PortuguÃ©s** manteniendo un Ãºnico modelo. [huggingface](https://huggingface.co/datasets/ruanchaves/b2w-reviews01)
- Uso de **RandomizedSearchCV** y **CalibratedClassifierCV** para obtener probabilidades confiables y selecciÃ³n automÃ¡tica de umbral.  

### ğŸ”¹ Fase 4 â€” SentimentAPI v4.0 (ES+PT + Backend)

- ConsolidaciÃ³n del pipeline multilingÃ¼e en `Proyecto_v12.ipynb` y generaciÃ³n del bundle productivo.  
- IntegraciÃ³n con backend Java, persistencia en PostgreSQL y preparaciÃ³n para explotaciÃ³n desde un Frontend de dashboards.  

***

## ğŸ““ Notebooks Principales

### 1. `Proyecto_v12.ipynb` â€” Modelo MultilingÃ¼e ES+PT (Core DS)

Este notebook implementa el pipeline completo de ML para **entrenamiento, calibraciÃ³n y serializaciÃ³n** del modelo multilingÃ¼e. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)

Incluye:

- Carga de datos estratificados (`train_es_pt.csv`, `validation_es_pt.csv`, `test_es_pt.csv`).  
- TransformaciÃ³n de `stars` (1â€“5) a sentimiento ternario (Negativo / Neutro / Positivo).  
- Limpieza de texto **Unicode-aware** y construcciÃ³n de `text_raw` / `text_clean`.  
- Pipeline:  
  - `TF-IDF` (nâ€‘grams, lÃ­mites de frecuencia, max_features).  
  - `LogisticRegression` + **CalibratedClassifierCV**.  
- SelecciÃ³n de **threshold Ã³ptimo** a partir de la relaciÃ³n coverage vs recall de la clase Negativo.  
- EvaluaciÃ³n global y por idioma (ES vs PT) y generaciÃ³n del artefacto `.joblib` con metadata (versiÃ³n, hash, parÃ¡metros).  

> ğŸ“‚ Nota: Los archivos `train_es_pt.csv`, `validation_es_pt.csv` y `test_es_pt.csv` se asumen presentes en el repositorio o accesibles vÃ­a enlace externo.  

### 2. `Consolidacion_de_dataset_multilingue_con_split_estratificado_train_validation_test.ipynb`

Notebook responsable de **unificar las fuentes de datos** y generar los splits estratificados para entrenamiento, validaciÃ³n y test. [huggingface](https://huggingface.co/datasets/ruanchaves/b2w-reviews01)

Hace:

- Carga de reseÃ±as en espaÃ±ol (`train.csv`) y portuguÃ©s (`reviews_consolidado_perfecto_v2.csv`).  
- NormalizaciÃ³n de columnas: `stars`, `review_title`, `review_body`, `language`.  
- ConstrucciÃ³n de `text_raw` y mapping `stars â†’ sentiment` (`Negativo`, `Neutro`, `Positivo`).  
- GeneraciÃ³n de un estrato `language||sentiment` y split 80/10/10 con `train_test_split` estratificado.  
- ExportaciÃ³n de:  
  - `train_es_pt.csv`  
  - `validation_es_pt.csv`  
  - `test_es_pt.csv`  

### 3. `Estructurar_datos_portugues.ipynb`

Este notebook **prepara y consolida los datos en portuguÃ©s** a partir de mÃºltiples fuentes externas. [github](https://github.com/luminati-io/eCommerce-dataset-samples)

- Usa reseÃ±as en portuguÃ©s de:  
  - [B2W-Reviews01 (Hugging Face)](https://huggingface.co/datasets/ruanchaves/b2w-reviews01). [huggingface](https://huggingface.co/datasets/ruanchaves/b2w-reviews01)
  - [Ecommerce product dataset â€“ MercadoLivre BR](https://github.com/octaprice/ecommerce-product-dataset/tree/main/data/mercadolivre_com_br). [github](https://github.com/luminati-io/eCommerce-dataset-samples)
- Combina estos datos con reseÃ±as en espaÃ±ol de [Amazon Reviews Multi](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi). [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)
- Genera el archivo consolidado multilingÃ¼e `reviews_consolidado_perfecto_v2.csv`, utilizado luego en el proceso de split estratificado.  

***

## ğŸ’» CÃ³mo ejecutar el modelo (entorno Data Science)

En **Visual Studio Code**, **Google Colab** o **Jupyter Notebook** puedes abrir y ejecutar `Proyecto_v12.ipynb`. [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)

1. AsegÃºrate de tener en la carpeta de trabajo los archivos:

   - `train_es_pt.csv`  
   - `validation_es_pt.csv`  
   - `test_es_pt.csv`  

2. Crea y activa tu entorno (ejemplo con `venv`):

```bash
python -m venv .venv
source .venv/bin/activate   # En Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

3. Ejecuta todas las celdas de `Proyecto_v12.ipynb` para:

- Entrenar el modelo multilingÃ¼e ES+PT.  
- Calibrar probabilidades.  
- Generar el artefacto `.joblib` con metadata y threshold Ã³ptimo.  

***

## ğŸŒ Origen de los datos multilingÃ¼es (ES + PT)

El dataset multilingÃ¼e ES+PT se construye en tres pasos: [github](https://github.com/luminati-io/eCommerce-dataset-samples)

1. **Datos en portuguÃ©s**  
   - ReseÃ±as tomadas desde:  
     - [B2W-Reviews01](https://huggingface.co/datasets/ruanchaves/b2w-reviews01). [huggingface](https://huggingface.co/datasets/ruanchaves/b2w-reviews01)
     - [Ecommerce product dataset â€“ MercadoLivre BR](https://github.com/octaprice/ecommerce-product-dataset/tree/main/data/mercadolivre_com_br). [github](https://github.com/luminati-io/eCommerce-dataset-samples)
   - Procesados y estandarizados en `Estructurar_datos_portugues.ipynb`.  

2. **Datos en espaÃ±ol**  
   - ReseÃ±as en espaÃ±ol del dataset [Amazon Reviews Multi](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi). [kaggle](https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi)

3. **ConsolidaciÃ³n y split estratificado**  
   - `Estructurar_datos_portugues.ipynb` genera `reviews_consolidado_perfecto_v2.csv` con reseÃ±as en ambos idiomas.  
   - `Consolidacion_de_dataset_multilingue_con_split_estratificado_train_validation_test.ipynb`:
     - Lee el consolidado y los archivos fuente.  
     - Crea el estrato `language||sentiment`.  
     - Realiza split 80/10/10 estratificado para **train/validation/test**.  
     - Exporta `train_es_pt.csv`, `validation_es_pt.csv`, `test_es_pt.csv`, usados luego en `Proyecto_v12.ipynb`.  

***

## ğŸ—ï¸ Arquitectura General

La soluciÃ³n completa combina el pipeline de ML en Python con un backend Java y persistencia en PostgreSQL. 

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SentimentAPI v4.0 (ES + PT)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“Š Data Science (Python)            ğŸ¿ Backend (Spring Boot)       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  â€¢ Notebooks de consolidaciÃ³n        â€¢ API REST /project/api/v2     â”‚
â”‚    y entrenamiento                   â€¢ IntegraciÃ³n con modelo       â”‚
â”‚  â€¢ TF-IDF + Logistic Regression        Python vÃ­a WebClient         â”‚
â”‚  â€¢ CalibraciÃ³n de probabilidades     â€¢ Persistencia en PostgreSQL   â”‚
â”‚  â€¢ Bundle .joblib + metadata         â€¢ Seguridad con BCrypt         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

***

## ğŸ”Œ Backend API y Persistencia

La versiÃ³n v4 incorpora un backend en Spring Boot con foco en **seguridad**, **persistencia** y **exposiciÃ³n de servicios** para el Frontend. 

### 1. Modelado de Base de Datos y Persistencia

- MigraciÃ³n a **PostgreSQL** con la base de datos `hackathonone` usando **Spring Data JPA`.  
- Entidades core:  
  - `User` y `Rol` para autenticaciÃ³n/autorizaciÃ³n.  
  - `Interaccion` para almacenar el historial de anÃ¡lisis de sentimientos.  
- Seguridad: uso de **BCrypt** para almacenar contraseÃ±as hash en lugar de texto plano.  

### 2. Endpoints y LÃ³gica de Negocio

- Servicios bajo el contexto:  
  - `/project/api/v2/usuario` para **registro** y **login**.  
- Procesamiento de sentimientos:  
  - El backend consume la API de Python mediante `WebClient`, obteniendo **etiqueta de sentimiento** y **score de confianza**.  
- Respuesta JSON estructurada que incluye:  
  - Texto analizado.  
  - Sentimiento predicho (Negativo / Neutro / Positivo).  
  - Probabilidad / score de confianza.  
  - Metadatos de la interacciÃ³n (usuario, timestamp, etc.).  

### 3. Conectividad y VisualizaciÃ³n (Backâ€“Front)

- El backend entrega **data cruda** lista para explotar.  
- El Frontend (React) se encarga de:  
  - Consumir el JSON retornado por la API.  
  - Agregar resultados (conteo de sentimientos, tendencias).  
  - Renderizar mÃ©tricas visuales usando librerÃ­as como **Chart.js** o **Recharts**.  

### 4. ConfiguraciÃ³n del Servidor

- Backend ejecutÃ¡ndose en el **puerto 8080**, con validaciones mediante **Jakarta Validation**.  
- MÃ¡s detalles de implementaciÃ³n en:  
  ğŸ‘‰ [Repositorio Backend â€“ SentimentAPI](https://github.com/Jona-9/SentimentAPI) 

***

## ğŸ’» Frontend â€“ Dashboards de Sentimiento

El cliente web para visualizaciÃ³n de mÃ©tricas y resultados de SentimentAPI v4.0 se encuentra en el siguiente repositorio: 

- ğŸ‘‰ **Repositorio anÃ¡lisis de sentimientos â€“ Rama Ale-dev**  
  https://github.com/Alexandracleto/sentimientos/tree/Ale-dev  

***

## ğŸ“¦ Archivos grandes (> 25 MB)

Por lÃ­mite de tamaÃ±o en GitHub, algunos artefactos y datasets se alojan externamente. 

- ğŸ‘‰ **Google Drive â€“ Artefactos y datasets SentimentAPI v4.0**  
  https://drive.google.com/drive/folders/1BJm3XgbgJzD-CzCSt2f5LFeIvOrIqwyB?usp=drive_link  

***

## ğŸš€ Flujo de EjecuciÃ³n (alto nivel)

1. **Consolidar dataset multilingÃ¼e**  
   - Ejecutar `Estructurar_datos_portugues.ipynb` y luego `Consolidacion_de_dataset_multilingue_con_split_estratificado_train_validation_test.ipynb` para generar `train_es_pt.csv`, `validation_es_pt.csv` y `test_es_pt.csv`.  

2. **Entrenar y calibrar el modelo**  
   - Ejecutar `Proyecto_v12.ipynb` para entrenar el modelo, realizar tuning/calibraciÃ³n y generar el artefacto `.joblib` con su metadata y threshold.  

3. **Integrar con Backend**  
   - Configurar la API Python para exponer el endpoint de inferencia.  
   - Levantar el backend Spring Boot, configurar PostgreSQL y revisar los endpoints `/project/api/v2/usuario` y los dedicados a anÃ¡lisis de sentimientos.  

4. **Consumir desde Frontend**  
   - Construir un cliente (React u otro) que consuma el JSON del backend y renderice dashboards de sentimiento y mÃ©tricas de confianza.  

***

## ğŸ“ Estructura del repositorio DS

```text
ğŸ“¦ sentimentapi-v4-es-pt/
â”œâ”€â”€ ğŸ““ Proyecto_v12.ipynb
â”œâ”€â”€ ğŸ““ Estructurar_datos_portugues.ipynb
â”œâ”€â”€ ğŸ““ Consolidacion_de_dataset_multilingue_con_split_estratificado_train_validation_test.ipynb
â”œâ”€â”€ ğŸ“Š train_es_pt.csv
â”œâ”€â”€ ğŸ“Š validation_es_pt.csv
â”œâ”€â”€ ğŸ“Š test_es_pt.csv
â”œâ”€â”€ ğŸ“Š reviews_consolidado_perfecto_v2.csv
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ LÃ­nea de tiempo del MVP de Data Science v1.docx
â””â”€â”€ ğŸ“¦ sentiment_bundle_es_pt_v2.joblib
```

***

## ğŸ‘¥ Equipo

Proyecto desarrollado por **â€œNo Data - No Codeâ€** en el marco del HackatÃ³n **No Country**, dentro del programa **Oracle Next Education (ONE)** en alianza con **Alura Latam**.

***

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia **MIT**.
